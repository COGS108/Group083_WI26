{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Saemi Namgung: Conceptualization, Analysis, Project administration, Writing – original draft,Writing – review & editing\n",
    "- Evelyn Na: Software, Data curation, Visualization, Methodology, Writing – review & editing\n",
    "- Jookyoung Lee: Conceptualization, Analysis, Project administration, Software, Writing - review & editing\n",
    "- Agam Chahal: Background research, Prior Research Analysis, Software\n",
    "- Alex Sun: Background research, Analysis, Proofreading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sleep deprivation is increasingly common among university students, potentially undermining the cognitive processes required for academic success. Therefore, we ask: Does average nightly sleep duration ($TotalSleepTime$) significantly predict end-of-semester GPA ($term\\_gpa$) for first-year college students when controlling for prior academic performance ($cum\\_gpa$) and demographic factors?",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sleep plays an essential role in cognition, memory, and learning. Research in neuroscience shows that sleep is an active process during which the brain consolidates newly learned information and strengthens memory. These processes are important for attention, executive function, and long-term learning, all of which are necessary for academic success. When sleep is inadequate or disrupted, these cognitive functions can be impaired, making it more difficult for students to perform well academically (<a href=\"https://www.nature.com/articles/nrn2762\" target=\"_blank\">Diekelmann & Born, 2010</a>).\n",
    "\n",
    "Several empirical studies have examined the relationship between sleep patterns and academic performance in student populations. An in-depth study of medical students found that ongoing sleep deprivation over a three-month period was associated with declines in academic scores, suggesting that reduced sleep may negatively affect academic outcomes (<a href=\"https://www.cureus.com/articles/380070-impact-of-sleep-deprivation-on-cognition-and-academic-scores-a-three-month-longitudinal-study-among-indian-medical-students\" target=\"_blank\">Impact of Sleep Deprivation on Cognition and Academic Scores, Cureus</a>). In addition, research by Gaultney (2017) found that among college students, sleep duration and sleep timing were associated with academic performance measures such as GPA (<a href=\"https://www.tandfonline.com/doi/full/10.1080/10963758.2017.1297713\" target=\"_blank\">Gaultney, 2017</a>). Together, these studies provide evidence that sleep behavior is meaningfully related to academic outcomes, though they differ in how thoroughly they control for other influencing factors. Although the relationship between sleep and academic performance has been studied before, this project does not aim to introduce a new theoretical idea. Instead, it focuses on confirming and extending existing findings using a data science approach and publicly available datasets. Many previous studies do not fully account for prior academic performance, which makes it harder to separate the effect of sleep from a student’s existing ability. By controlling for prior GPA and demographic factors, our analysis examines whether sleep duration remains a meaningful predictor of end-of-semester GPA.\n",
    "\n",
    "To better understand the specific contribution of sleep to academic success, researchers recommend controlling for prior academic performance and relevant demographic variables. Prior GPA is a strong predictor of future academic outcomes and should be included in analytical models to avoid attributing existing differences in ability to sleep alone. By using regression models that incorporate prior performance and demographic controls, it becomes possible to evaluate whether sleep duration remains a significant predictor of end-of-semester GPA. This project follows that approach by examining the relationship between average nightly sleep duration and semester GPA while accounting for baseline academic performance and demographic factors.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that average nightly sleep duration ($TotalSleepTime$) will be a positive and significant predictor of end-of-semester GPA ($term\\_gpa$), such that an increase in sleep duration is associated with higher academic achievement even when controlling for prior performance ($cum\\_gpa$) and demographic factors. This expectation is grounded in the established neurobiological role of sleep in memory consolidation, executive function, and emotional regulation, all of which are critical for the high-level cognitive processing required to succeed in a college environment. By accounting for baseline academic ability and course load, we aim to isolate the specific impact that sleep hygiene has on a student's ability to maintain and improve their grades."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name: Nightly sleep time and GPA in first-years\n",
    "  - Link to the dataset: https://cmustatistics.github.io/data-repository/psychology/cmu-sleep.html \n",
    "  - Number of observations: There were a total of 634 participants in this study, who each received a Fitbit to track their sleep and physical activity.\n",
    "  - Number of variables: 15\n",
    "  - Description of the variables most relevant to this project\n",
    "    - TotalSleepTime (Primary Predictor): Average nightly sleep duration in minutes, calculated from the main sleep episode.\n",
    "    - term_gpa (Outcome): End-of-term GPA for the semester being studied, used as the measure of academic performance.\n",
    "    - cum_gpa (Control): Prior cumulative GPA, used to account for baseline academic ability.\n",
    "    - Zterm_units_ZofZ (Control): Standardized course load relative to the student's cohort.\n",
    "    - demo_gender, demo_race, demo_firstgen (Controls): Demographic identifiers used to account for institutional and systemic factors.\n",
    "    - frac_nights_with_data (Data Quality): Used to filter subjects with insufficient or unreliable sleep tracking data.\n",
    "  - Descriptions of any shortcomings this dataset has with respect to the project:\n",
    "    - Selection Bias: The data only includes students who opted into wearing a Fitbit, which may exclude specific demographics or those with extremely irregular schedules.\n",
    "    - Generalizability: The participants are from three specific, high-ranking universities, meaning the results may not generalize to students at community colleges or different institutional types.\n",
    "    - Measurement Error: Fitbit data, while objective, can occasionally misclassify periods of quiet rest as sleep or fail due to battery depletion, which could introduce noise into the TotalSleepTime variable.\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets. (N/A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://cmustatistics.github.io/data-repository/psychology/cmu-sleep.csv', 'filename':'cmu-sleep.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sleep Patterns and Academic Performance\n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (634, 15)\n",
      "\n",
      "Missing values per column:\n",
      "term_gpa            0\n",
      "cum_gpa             0\n",
      "TotalSleepTime      0\n",
      "term_units          0\n",
      "Zterm_units_ZofZ    0\n",
      "demo_race           0\n",
      "demo_gender         0\n",
      "demo_firstgen       0\n",
      "dtype: int64\n",
      "\n",
      "Final shape after cleaning: (634, 15)\n",
      "\n",
      "Summary statistics:\n",
      "         subject_id       study  bedtime_mssd  TotalSleepTime  midpoint_sleep  \\\n",
      "count    634.000000  634.000000    634.000000      634.000000      634.000000   \n",
      "mean   13005.892744    3.181388      0.451688      397.323874      398.679186   \n",
      "std    26496.593477    1.317125      1.393632       50.856725       72.710945   \n",
      "min        1.000000    1.000000      0.004505      194.782609      247.071429   \n",
      "25%      178.000000    2.000000      0.074694      366.930077      345.182692   \n",
      "50%      358.500000    3.000000      0.135007      400.395833      388.245726   \n",
      "75%      592.750000    4.000000      0.291698      430.114583      437.655263   \n",
      "max    99978.000000    5.000000     20.849225      587.666667      724.666667   \n",
      "\n",
      "       frac_nights_with_data  daytime_sleep     cum_gpa    term_gpa  \\\n",
      "count             634.000000     634.000000  634.000000  634.000000   \n",
      "mean                0.867439      41.164241    3.465596    3.449598   \n",
      "std                 0.178960      27.389418    0.437577    0.500467   \n",
      "min                 0.214286       2.269231    1.210000    0.350000   \n",
      "25%                 0.821429      23.097826    3.232283    3.233333   \n",
      "50%                 0.932184      34.982143    3.557833    3.555667   \n",
      "75%                 1.000000      51.248538    3.789545    3.810000   \n",
      "max                 1.000000     292.304348    4.000000    4.000000   \n",
      "\n",
      "       term_units  Zterm_units_ZofZ  \n",
      "count  487.000000      4.870000e+02  \n",
      "mean    29.392197      1.437371e-11  \n",
      "std     17.642780      1.000000e+00  \n",
      "min      5.000000     -3.982521e+00  \n",
      "25%     15.000000     -5.510418e-01  \n",
      "50%     17.000000      4.120711e-02  \n",
      "75%     48.000000      5.602710e-01  \n",
      "max     73.000000      4.055295e+00  \n",
      "\n",
      "Interim dataset saved to data/01-interim/cmu_sleep_interim.csv\n",
      "\n",
      "Data cleaning complete.\n",
      "___________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_27396\">\n",
       "  <caption>Dataset shapes (before vs after cleaning)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_27396_level0_col0\" class=\"col_heading level0 col0\" >Dataset</th>\n",
       "      <th id=\"T_27396_level0_col1\" class=\"col_heading level0 col1\" >Rows</th>\n",
       "      <th id=\"T_27396_level0_col2\" class=\"col_heading level0 col2\" >Cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_27396_row0_col0\" class=\"data row0 col0\" >Raw</td>\n",
       "      <td id=\"T_27396_row0_col1\" class=\"data row0 col1\" >634</td>\n",
       "      <td id=\"T_27396_row0_col2\" class=\"data row0 col2\" >15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_27396_row1_col0\" class=\"data row1 col0\" >Cleaned</td>\n",
       "      <td id=\"T_27396_row1_col1\" class=\"data row1 col1\" >634</td>\n",
       "      <td id=\"T_27396_row1_col2\" class=\"data row1 col2\" >15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff44f8a0410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5809a_row0_col1, #T_5809a_row1_col1 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 100.0%, transparent 100.0%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5809a\">\n",
       "  <caption>Missing values by column</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5809a_level0_col0\" class=\"col_heading level0 col0\" >missing_count</th>\n",
       "      <th id=\"T_5809a_level0_col1\" class=\"col_heading level0 col1\" >missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5809a_level0_row0\" class=\"row_heading level0 row0\" >term_units</th>\n",
       "      <td id=\"T_5809a_row0_col0\" class=\"data row0 col0\" >147</td>\n",
       "      <td id=\"T_5809a_row0_col1\" class=\"data row0 col1\" >23.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5809a_level0_row1\" class=\"row_heading level0 row1\" >Zterm_units_ZofZ</th>\n",
       "      <td id=\"T_5809a_row1_col0\" class=\"data row1 col0\" >147</td>\n",
       "      <td id=\"T_5809a_row1_col1\" class=\"data row1 col1\" >23.19%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff44fd85110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e5c0b\">\n",
       "  <caption>Summary statistics (numeric columns)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e5c0b_level0_col0\" class=\"col_heading level0 col0\" >n</th>\n",
       "      <th id=\"T_e5c0b_level0_col1\" class=\"col_heading level0 col1\" >mean</th>\n",
       "      <th id=\"T_e5c0b_level0_col2\" class=\"col_heading level0 col2\" >std</th>\n",
       "      <th id=\"T_e5c0b_level0_col3\" class=\"col_heading level0 col3\" >min</th>\n",
       "      <th id=\"T_e5c0b_level0_col4\" class=\"col_heading level0 col4\" >p25</th>\n",
       "      <th id=\"T_e5c0b_level0_col5\" class=\"col_heading level0 col5\" >median</th>\n",
       "      <th id=\"T_e5c0b_level0_col6\" class=\"col_heading level0 col6\" >p75</th>\n",
       "      <th id=\"T_e5c0b_level0_col7\" class=\"col_heading level0 col7\" >max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e5c0b_level0_row0\" class=\"row_heading level0 row0\" >subject_id</th>\n",
       "      <td id=\"T_e5c0b_row0_col0\" class=\"data row0 col0\" >634.000</td>\n",
       "      <td id=\"T_e5c0b_row0_col1\" class=\"data row0 col1\" >13,005.893</td>\n",
       "      <td id=\"T_e5c0b_row0_col2\" class=\"data row0 col2\" >26,496.593</td>\n",
       "      <td id=\"T_e5c0b_row0_col3\" class=\"data row0 col3\" >1.000</td>\n",
       "      <td id=\"T_e5c0b_row0_col4\" class=\"data row0 col4\" >178.000</td>\n",
       "      <td id=\"T_e5c0b_row0_col5\" class=\"data row0 col5\" >358.500</td>\n",
       "      <td id=\"T_e5c0b_row0_col6\" class=\"data row0 col6\" >592.750</td>\n",
       "      <td id=\"T_e5c0b_row0_col7\" class=\"data row0 col7\" >99,978.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5c0b_level0_row1\" class=\"row_heading level0 row1\" >study</th>\n",
       "      <td id=\"T_e5c0b_row1_col0\" class=\"data row1 col0\" >634.000</td>\n",
       "      <td id=\"T_e5c0b_row1_col1\" class=\"data row1 col1\" >3.181</td>\n",
       "      <td id=\"T_e5c0b_row1_col2\" class=\"data row1 col2\" >1.317</td>\n",
       "      <td id=\"T_e5c0b_row1_col3\" class=\"data row1 col3\" >1.000</td>\n",
       "      <td id=\"T_e5c0b_row1_col4\" class=\"data row1 col4\" >2.000</td>\n",
       "      <td id=\"T_e5c0b_row1_col5\" class=\"data row1 col5\" >3.000</td>\n",
       "      <td id=\"T_e5c0b_row1_col6\" class=\"data row1 col6\" >4.000</td>\n",
       "      <td id=\"T_e5c0b_row1_col7\" class=\"data row1 col7\" >5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5c0b_level0_row2\" class=\"row_heading level0 row2\" >bedtime_mssd</th>\n",
       "      <td id=\"T_e5c0b_row2_col0\" class=\"data row2 col0\" >634.000</td>\n",
       "      <td id=\"T_e5c0b_row2_col1\" class=\"data row2 col1\" >0.452</td>\n",
       "      <td id=\"T_e5c0b_row2_col2\" class=\"data row2 col2\" >1.394</td>\n",
       "      <td id=\"T_e5c0b_row2_col3\" class=\"data row2 col3\" >0.005</td>\n",
       "      <td id=\"T_e5c0b_row2_col4\" class=\"data row2 col4\" >0.075</td>\n",
       "      <td id=\"T_e5c0b_row2_col5\" class=\"data row2 col5\" >0.135</td>\n",
       "      <td id=\"T_e5c0b_row2_col6\" class=\"data row2 col6\" >0.292</td>\n",
       "      <td id=\"T_e5c0b_row2_col7\" class=\"data row2 col7\" >20.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5c0b_level0_row3\" class=\"row_heading level0 row3\" >TotalSleepTime</th>\n",
       "      <td id=\"T_e5c0b_row3_col0\" class=\"data row3 col0\" >634.000</td>\n",
       "      <td id=\"T_e5c0b_row3_col1\" class=\"data row3 col1\" >397.324</td>\n",
       "      <td id=\"T_e5c0b_row3_col2\" class=\"data row3 col2\" >50.857</td>\n",
       "      <td id=\"T_e5c0b_row3_col3\" class=\"data row3 col3\" >194.783</td>\n",
       "      <td id=\"T_e5c0b_row3_col4\" class=\"data row3 col4\" >366.930</td>\n",
       "      <td id=\"T_e5c0b_row3_col5\" class=\"data row3 col5\" >400.396</td>\n",
       "      <td id=\"T_e5c0b_row3_col6\" class=\"data row3 col6\" >430.115</td>\n",
       "      <td id=\"T_e5c0b_row3_col7\" class=\"data row3 col7\" >587.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5c0b_level0_row4\" class=\"row_heading level0 row4\" >midpoint_sleep</th>\n",
       "      <td id=\"T_e5c0b_row4_col0\" class=\"data row4 col0\" >634.000</td>\n",
       "      <td id=\"T_e5c0b_row4_col1\" class=\"data row4 col1\" >398.679</td>\n",
       "      <td id=\"T_e5c0b_row4_col2\" class=\"data row4 col2\" >72.711</td>\n",
       "      <td id=\"T_e5c0b_row4_col3\" class=\"data row4 col3\" >247.071</td>\n",
       "      <td id=\"T_e5c0b_row4_col4\" class=\"data row4 col4\" >345.183</td>\n",
       "      <td id=\"T_e5c0b_row4_col5\" class=\"data row4 col5\" >388.246</td>\n",
       "      <td id=\"T_e5c0b_row4_col6\" class=\"data row4 col6\" >437.655</td>\n",
       "      <td id=\"T_e5c0b_row4_col7\" class=\"data row4 col7\" >724.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5c0b_level0_row5\" class=\"row_heading level0 row5\" >frac_nights_with_data</th>\n",
       "      <td id=\"T_e5c0b_row5_col0\" class=\"data row5 col0\" >634.000</td>\n",
       "      <td id=\"T_e5c0b_row5_col1\" class=\"data row5 col1\" >0.867</td>\n",
       "      <td id=\"T_e5c0b_row5_col2\" class=\"data row5 col2\" >0.179</td>\n",
       "      <td id=\"T_e5c0b_row5_col3\" class=\"data row5 col3\" >0.214</td>\n",
       "      <td id=\"T_e5c0b_row5_col4\" class=\"data row5 col4\" >0.821</td>\n",
       "      <td id=\"T_e5c0b_row5_col5\" class=\"data row5 col5\" >0.932</td>\n",
       "      <td id=\"T_e5c0b_row5_col6\" class=\"data row5 col6\" >1.000</td>\n",
       "      <td id=\"T_e5c0b_row5_col7\" class=\"data row5 col7\" >1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5c0b_level0_row6\" class=\"row_heading level0 row6\" >daytime_sleep</th>\n",
       "      <td id=\"T_e5c0b_row6_col0\" class=\"data row6 col0\" >634.000</td>\n",
       "      <td id=\"T_e5c0b_row6_col1\" class=\"data row6 col1\" >41.164</td>\n",
       "      <td id=\"T_e5c0b_row6_col2\" class=\"data row6 col2\" >27.389</td>\n",
       "      <td id=\"T_e5c0b_row6_col3\" class=\"data row6 col3\" >2.269</td>\n",
       "      <td id=\"T_e5c0b_row6_col4\" class=\"data row6 col4\" >23.098</td>\n",
       "      <td id=\"T_e5c0b_row6_col5\" class=\"data row6 col5\" >34.982</td>\n",
       "      <td id=\"T_e5c0b_row6_col6\" class=\"data row6 col6\" >51.249</td>\n",
       "      <td id=\"T_e5c0b_row6_col7\" class=\"data row6 col7\" >292.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5c0b_level0_row7\" class=\"row_heading level0 row7\" >cum_gpa</th>\n",
       "      <td id=\"T_e5c0b_row7_col0\" class=\"data row7 col0\" >634.000</td>\n",
       "      <td id=\"T_e5c0b_row7_col1\" class=\"data row7 col1\" >3.466</td>\n",
       "      <td id=\"T_e5c0b_row7_col2\" class=\"data row7 col2\" >0.438</td>\n",
       "      <td id=\"T_e5c0b_row7_col3\" class=\"data row7 col3\" >1.210</td>\n",
       "      <td id=\"T_e5c0b_row7_col4\" class=\"data row7 col4\" >3.232</td>\n",
       "      <td id=\"T_e5c0b_row7_col5\" class=\"data row7 col5\" >3.558</td>\n",
       "      <td id=\"T_e5c0b_row7_col6\" class=\"data row7 col6\" >3.790</td>\n",
       "      <td id=\"T_e5c0b_row7_col7\" class=\"data row7 col7\" >4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5c0b_level0_row8\" class=\"row_heading level0 row8\" >term_gpa</th>\n",
       "      <td id=\"T_e5c0b_row8_col0\" class=\"data row8 col0\" >634.000</td>\n",
       "      <td id=\"T_e5c0b_row8_col1\" class=\"data row8 col1\" >3.450</td>\n",
       "      <td id=\"T_e5c0b_row8_col2\" class=\"data row8 col2\" >0.500</td>\n",
       "      <td id=\"T_e5c0b_row8_col3\" class=\"data row8 col3\" >0.350</td>\n",
       "      <td id=\"T_e5c0b_row8_col4\" class=\"data row8 col4\" >3.233</td>\n",
       "      <td id=\"T_e5c0b_row8_col5\" class=\"data row8 col5\" >3.556</td>\n",
       "      <td id=\"T_e5c0b_row8_col6\" class=\"data row8 col6\" >3.810</td>\n",
       "      <td id=\"T_e5c0b_row8_col7\" class=\"data row8 col7\" >4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5c0b_level0_row9\" class=\"row_heading level0 row9\" >term_units</th>\n",
       "      <td id=\"T_e5c0b_row9_col0\" class=\"data row9 col0\" >487.000</td>\n",
       "      <td id=\"T_e5c0b_row9_col1\" class=\"data row9 col1\" >29.392</td>\n",
       "      <td id=\"T_e5c0b_row9_col2\" class=\"data row9 col2\" >17.643</td>\n",
       "      <td id=\"T_e5c0b_row9_col3\" class=\"data row9 col3\" >5.000</td>\n",
       "      <td id=\"T_e5c0b_row9_col4\" class=\"data row9 col4\" >15.000</td>\n",
       "      <td id=\"T_e5c0b_row9_col5\" class=\"data row9 col5\" >17.000</td>\n",
       "      <td id=\"T_e5c0b_row9_col6\" class=\"data row9 col6\" >48.000</td>\n",
       "      <td id=\"T_e5c0b_row9_col7\" class=\"data row9 col7\" >73.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e5c0b_level0_row10\" class=\"row_heading level0 row10\" >Zterm_units_ZofZ</th>\n",
       "      <td id=\"T_e5c0b_row10_col0\" class=\"data row10 col0\" >487.000</td>\n",
       "      <td id=\"T_e5c0b_row10_col1\" class=\"data row10 col1\" >0.000</td>\n",
       "      <td id=\"T_e5c0b_row10_col2\" class=\"data row10 col2\" >1.000</td>\n",
       "      <td id=\"T_e5c0b_row10_col3\" class=\"data row10 col3\" >-3.983</td>\n",
       "      <td id=\"T_e5c0b_row10_col4\" class=\"data row10 col4\" >-0.551</td>\n",
       "      <td id=\"T_e5c0b_row10_col5\" class=\"data row10 col5\" >0.041</td>\n",
       "      <td id=\"T_e5c0b_row10_col6\" class=\"data row10 col6\" >0.560</td>\n",
       "      <td id=\"T_e5c0b_row10_col7\" class=\"data row10 col7\" >4.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff4501e50d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0f12a\">\n",
       "  <caption>Course load columns coverage (units)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_0f12a_level0_col0\" class=\"col_heading level0 col0\" >column</th>\n",
       "      <th id=\"T_0f12a_level0_col1\" class=\"col_heading level0 col1\" >non_null_count</th>\n",
       "      <th id=\"T_0f12a_level0_col2\" class=\"col_heading level0 col2\" >non_null_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_0f12a_row0_col0\" class=\"data row0 col0\" >term_units</td>\n",
       "      <td id=\"T_0f12a_row0_col1\" class=\"data row0 col1\" >487</td>\n",
       "      <td id=\"T_0f12a_row0_col2\" class=\"data row0 col2\" >76.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0f12a_row1_col0\" class=\"data row1 col0\" >Zterm_units_ZofZ</td>\n",
       "      <td id=\"T_0f12a_row1_col1\" class=\"data row1 col1\" >487</td>\n",
       "      <td id=\"T_0f12a_row1_col2\" class=\"data row1 col2\" >76.81%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff44f7e04d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# TotalSleepTime → term_gpa (controlling for cum_gpa + demographics)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "#print(os.getcwd())\n",
    "#!ls data/00-raw\n",
    "\n",
    "\n",
    "# Load raw dataset\n",
    "\n",
    "\n",
    "\n",
    "df_raw = pd.read_csv(\"data/00-raw/cmu-sleep.csv\")\n",
    "\n",
    "print(\"Initial shape:\", df_raw.shape)\n",
    "\n",
    "\n",
    "# Check missing values for key variables\n",
    "\n",
    "key_columns = [\n",
    "    'term_gpa',\n",
    "    'cum_gpa',\n",
    "    'TotalSleepTime',\n",
    "    'term_units',\n",
    "    'Zterm_units_ZofZ',\n",
    "    'demo_race',\n",
    "    'demo_gender',\n",
    "    'demo_firstgen'\n",
    "]\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df_raw[key_columns].isna().sum())\n",
    "\n",
    "# Drop rows missing key variables\n",
    "\n",
    "df_clean = df_raw.dropna(subset=[\n",
    "    'term_gpa',\n",
    "    'cum_gpa',\n",
    "    'TotalSleepTime'\n",
    "]).copy()\n",
    "\n",
    "\n",
    "numeric_cols = [\n",
    "    'term_gpa',\n",
    "    'cum_gpa',\n",
    "    'TotalSleepTime',\n",
    "    'term_units',\n",
    "    'Zterm_units_ZofZ'\n",
    "]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "\n",
    "# Remove impossible GPA values\n",
    "\n",
    "df_clean = df_clean[\n",
    "    (df_clean['term_gpa'] >= 0) & (df_clean['term_gpa'] <= 4)\n",
    "]\n",
    "\n",
    "df_clean = df_clean[\n",
    "    (df_clean['cum_gpa'] >= 0) & (df_clean['cum_gpa'] <= 4)\n",
    "]\n",
    "\n",
    "# ------------------------------------------\n",
    "# Remove unrealistic sleep values. Unsure if we should keep/leave yet. Miniscule amounts of sleep aren't uncommon in college.\n",
    "# ------------------------------------------\n",
    "# df_clean = df_clean[\n",
    "#     (df_clean['TotalSleepTime'] >= 120) & \n",
    "#     (df_clean['TotalSleepTime'] <= 900)\n",
    "# ]\n",
    "\n",
    "\n",
    "# Remove duplicates\n",
    "\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "\n",
    "\n",
    "# Final Dataset Summary\n",
    "\n",
    "print(\"\\nFinal shape after cleaning:\", df_clean.shape)\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df_clean.describe())\n",
    "\n",
    "# ------------------------------------------\n",
    "# Save cleaned dataset to 01-interim\n",
    "# ------------------------------------------\n",
    "df_clean.to_csv(\"data/01-interim/cmu_sleep_interim.csv\", index=False)\n",
    "\n",
    "print(\"\\nInterim dataset saved to data/01-interim/cmu_sleep_interim.csv\")\n",
    "print(\"\\nData cleaning complete.\")\n",
    "\n",
    "\n",
    "print(\"___________________________________________________\")\n",
    "shape_tbl = pd.DataFrame({\n",
    "    \"Dataset\": [\"Raw\", \"Cleaned\"],\n",
    "    \"Rows\": [df_raw.shape[0], df_clean.shape[0]],\n",
    "    \"Cols\": [df_raw.shape[1], df_clean.shape[1]],\n",
    "})\n",
    "\n",
    "display(\n",
    "    shape_tbl.style\n",
    "    .hide(axis=\"index\")\n",
    "    .set_caption(\"Dataset shapes (before vs after cleaning)\")\n",
    ")\n",
    "\n",
    "# Missingness (count + %)\n",
    "miss = pd.DataFrame({\n",
    "    \"missing_count\": df_clean.isna().sum(),\n",
    "    \"missing_pct\": (df_clean.isna().mean() * 100)\n",
    "}).sort_values(\"missing_count\", ascending=False)\n",
    "\n",
    "miss_show = miss[miss[\"missing_count\"] > 0].copy()\n",
    "if miss_show.empty:\n",
    "    miss_show = pd.DataFrame({\"missing_count\": [0], \"missing_pct\": [0.0]}, index=[\"(no missing values)\"])\n",
    "\n",
    "display(\n",
    "    miss_show.style\n",
    "    .format({\"missing_count\": \"{:,.0f}\", \"missing_pct\": \"{:.2f}%\"})\n",
    "    .bar(subset=[\"missing_pct\"])\n",
    "    .set_caption(\"Missing values by column\")\n",
    ")\n",
    "\n",
    "# Summary stats\n",
    "# Show numeric columns only, rounded\n",
    "desc = df_clean.describe(include=[np.number]).T\n",
    "desc = desc.rename(columns={\n",
    "    \"count\": \"n\", \"mean\": \"mean\", \"std\": \"std\", \"min\": \"min\",\n",
    "    \"25%\": \"p25\", \"50%\": \"median\", \"75%\": \"p75\", \"max\": \"max\"\n",
    "})\n",
    "\n",
    "display(\n",
    "    desc.style\n",
    "    .format(\"{:,.3f}\")\n",
    "    .set_caption(\"Summary statistics (numeric columns)\")\n",
    ")\n",
    "\n",
    "# Units coverage",
    "units_cols = [c for c in [\"term_units\", \"Zterm_units_ZofZ\"] if c in df_clean.columns]\n",
    "if units_cols:\n",
    "    units_cov = pd.DataFrame({\n",
    "        \"column\": units_cols,\n",
    "        \"non_null_count\": [df_clean[c].notna().sum() for c in units_cols],\n",
    "        \"non_null_pct\": [df_clean[c].notna().mean() * 100 for c in units_cols],\n",
    "    })\n",
    "    display(\n",
    "        units_cov.style\n",
    "        .hide(axis=\"index\")\n",
    "        .format({\"non_null_count\": \"{:,.0f}\", \"non_null_pct\": \"{:.2f}%\"})\n",
    "        .set_caption(\"Course load columns coverage (units)\")\n",
    "    )\n",
    "else:\n",
    "    print(\"term_units / Zterm_units_ZofZ not found in df columns.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aschahal/Group083_WI26\n",
      "cmu-sleep.csv\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
  "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "> This study involves human subjects and includes sensitive academic and behavioral data such as sleep duration, GPA, and demographic characteristics. Direct student data collection will require informed consent, which includes a detailed explanation of the study's objectives, the data's purpose, and the fact that participation is entirely voluntary. Participants will be told that participation or non-participation will not have an impact on their academic status.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "> Self-reported sleep data may add social desirability bias or recollection bias. Also, there may be systematic differences between students who decide to participate and who do not (e.g., more academically engaged kids). The results will be cautiously interpreted, and these limitations will be noted.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "> Personally identifiable information will not be collected or retained. Only the variables necessary for the research question will be included, and all data will be anonymized before analysis.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "> Rather than drawing inferences regarding group differences, demographic characteristics are included in order to adjust for confounding effects. Their inclusion helps prevent erroneous findings caused by omitted variable bias and permits investigation of whether observed connections differ between groups.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "> Data will be stored on secure, access-restricted systems used for academic research. Only authorized members of the research team will have access to the dataset.\n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "> If data are collected directly from participants, individuals will be informed that they may request removal of their data prior to anonymization and analysis.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "> Data will be retained only for the duration of the course project and deleted afterward in accordance with course and institutional guidelines.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "> This analysis acknowledges that sleep duration is only one of many factors influencing academic performance. Limitations are examined in relation to broader contextual variables like workload, financial stress, mental health, and institutional assistance.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "> Prior academic performance (cumulative GPA) is included as a control variable to reduce confounding. Remaining limitations due to unobserved variables will be explicitly acknowledged.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "> Results will be presented transparently, emphasizing effect sizes and uncertainty rather than overstating significance.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "> No personally identifiable information will be used or displayed in analysis outputs.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "> The analysis workflow will be documented and reproducible, allowing results to be reviewed or re-run if concerns arise.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "> Instead of generating predictions or making decisions, the model makes use of demographic characteristics, sleep duration, and past GPA for statistical adjustment. Individual-level evaluations are made without the use of variables.\n",
    "\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "> This study is not primarily concerned with group-level differences. To make sure results are not false, interaction effects and subgroup trends could be investigated descriptively.\n",
    "\n",
    " - [ ] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "> The coefficients of the regression model can be interpreted in terms of correlations between GPA and sleep duration.\n",
    "\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "> Limitations such as correlational design, potential measurement error, and omitted variables will be clearly stated.\n",
    "\n",
    "### E. Deployment\n",
    " - [ ] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " - [ ] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [ ] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "> This research is not meant to be used in situations when decisions must be made. However, there is a risk that results could be misused to blame students or enforce rigid behavioral expectations. Findings will be presented as informative rather than prescriptive, with a focus on wellness-oriented and helpful interpretations, in order to reduce this.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Communication:**\n",
    "  Our team will communicate primarily through **messaging** for updates and questions, and **Zoom** for meetings. Team members are expected to check messages regularly and respond within 12 hours on weekdays and 24 hours on weekends. We will hold **weekly/bi-weekly Zoom meetings** to discuss progress, assign tasks, and address questions or concerns.\n",
    "\n",
    "- **Respectful Collaboration:**\n",
    "  We agree to communicate respectfully and constructively, especially when giving feedback or disagreeing. We assume all feedback is well-intentioned and aimed at improving the project.\n",
    "\n",
    "- **Equal Contribution and Accountability:**\n",
    "  All team members are expected to contribute equally in effort across the project. While roles may differ based on strengths (e.g., coding, writing, analysis), everyone will participate in coding, writing, and editing at some point. Team members will complete assigned tasks by agreed-upon deadlines and communicate early if they are struggling.\n",
    "\n",
    "- **Decision Making:**\n",
    "  Most decisions will be made through group discussion and consensus or majority agreement. For time-sensitive decisions, the team member responsible for that section may make the decision and update the group afterward.\n",
    "\n",
    "- **Handling Conflict and Challenges:**\n",
    "  If conflicts arise, we will address them openly and respectfully as a group. If a team member is unable to meet expectations, they are expected to notify the group as soon as possible so responsibilities can be adjusted. If issues persist, we will follow the course guidelines for addressing problem teammates.\n",
    "\n",
    "By contributing to this project and adding our names to the submission, we confirm that we have read the COGS108 Team Policies, agree to these expectations, and intend to fulfill them throughout the quarter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/4  |  1 PM | Each member worked on assigned sections of the project proposal (research question, data, ethics, team expectations, timeline)  | Discuss and finalize research question; review proposal sections; allocate responsibilities to each team member | \n",
    "| 2/11  |  7 PM |  Identify and explore dataset; conduct preliminary data inspection; review background literature | Discuss dataset suitability and ethics; finalize variables; confirm overall analysis plan | \n",
    "| 2/18  | 7 PM  | Complete data wrangling and exploratory data analysis (EDA); draft initial visualizations  | Review and edit wrangling/EDA; discuss patterns and potential issues; refine analysis and visualization approach   |\n",
    "| 3/4  | 7 PM  | Conduct main statistical analysis; update visualizations; draft results section | Discuss analysis results; interpret findings; plan discussion and conclusion sections   |\n",
    "| 3/11  | 7 PM  | Draft full project (results, discussion, conclusion); integrate feedback | Review full project draft; finalize writing, figures, and interpretations |\n",
    "| 3/18  | Before 11:59 PM  | Final edits and checks completed | Submit Final Project and complete Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
